{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ruby Code Complexity Embedding Visualization\n",
    "\n",
    "This notebook analyzes the learned graph embeddings from our Graph Neural Network model trained on Ruby method complexity prediction. We will:\n",
    "\n",
    "1. Load the trained GNN model\n",
    "2. Extract graph-level embeddings from the test dataset\n",
    "3. Use t-SNE to project high-dimensional embeddings to 2D space\n",
    "4. Visualize the embeddings colored by complexity scores to check for clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.manifold import TSNE\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.nn import global_mean_pool\n",
    "\n",
    "# Add src directory to path\n",
    "sys.path.insert(0, os.path.join('..', 'src'))\n",
    "\n",
    "from data_processing import RubyASTDataset\n",
    "from models import RubyComplexityGNN\n",
    "\n",
    "# Set style for better plots\n",
    "plt.style.use('default')\n",
    "sns.set_palette(\"viridis\")\n",
    "\n",
    "print(\"üì¶ Libraries loaded successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load the Trained Model\n",
    "\n",
    "First, we'll load our best trained GNN model that was saved during training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the trained model checkpoint\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "checkpoint = torch.load('../best_model.pt', map_location=device)\n",
    "\n",
    "print(\"üèÜ Best Model Information:\")\n",
    "print(f\"   Epoch: {checkpoint['epoch']}\")\n",
    "print(f\"   Validation Loss: {checkpoint['val_loss']:.4f}\")\n",
    "print(f\"   Model Config: {checkpoint['model_config']}\")\n",
    "\n",
    "# Initialize model with the same configuration\n",
    "model_config = checkpoint['model_config']\n",
    "model = RubyComplexityGNN(\n",
    "    input_dim=model_config['input_dim'],\n",
    "    hidden_dim=model_config['hidden_dim'], \n",
    "    num_layers=model_config['num_layers'],\n",
    "    conv_type=model_config['conv_type'],\n",
    "    dropout=model_config['dropout']\n",
    ").to(device)\n",
    "\n",
    "# Load the trained weights\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "model.eval()\n",
    "\n",
    "print(f\"\\n‚úÖ Model loaded successfully on {device}\")\n",
    "print(f\"   Parameters: {sum(p.numel() for p in model.parameters()):,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Create Embedding Extraction Function\n",
    "\n",
    "We need to modify the model's forward pass to extract embeddings after the global pooling layer but before the final prediction layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_embeddings(model, data):\n",
    "    \"\"\"\n",
    "    Extract graph-level embeddings from the model before the final prediction layer.\n",
    "    \n",
    "    Args:\n",
    "        model: The trained GNN model\n",
    "        data: PyTorch Geometric Data object\n",
    "        \n",
    "    Returns:\n",
    "        embeddings: Graph-level embeddings from global pooling layer\n",
    "        predictions: Final complexity predictions\n",
    "    \"\"\"\n",
    "    x, edge_index, batch = data.x, data.edge_index, data.batch\n",
    "    \n",
    "    # Apply convolution layers (same as model.forward)\n",
    "    for i, conv in enumerate(model.convs):\n",
    "        x = conv(x, edge_index)\n",
    "        if i < len(model.convs) - 1:  # No activation after last layer\n",
    "            x = torch.nn.functional.relu(x)\n",
    "            x = torch.nn.functional.dropout(x, p=model.dropout, training=model.training)\n",
    "    \n",
    "    # Global pooling to get graph-level representation (THIS IS WHAT WE WANT)\n",
    "    embeddings = global_mean_pool(x, batch)\n",
    "    \n",
    "    # Final prediction\n",
    "    predictions = model.predictor(embeddings)\n",
    "    \n",
    "    return embeddings, predictions\n",
    "\n",
    "print(\"üîß Embedding extraction function created!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Load Test Dataset and Extract Embeddings\n",
    "\n",
    "Now we'll load the test dataset and pass it through our model to extract the graph-level embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load test dataset\n",
    "test_dataset = RubyASTDataset('../dataset/test.jsonl')\n",
    "print(f\"üìä Loaded {len(test_dataset)} test samples\")\n",
    "\n",
    "# Extract embeddings and predictions for all test samples\n",
    "all_embeddings = []\n",
    "all_predictions = []\n",
    "all_true_complexity = []\n",
    "all_metadata = []\n",
    "\n",
    "print(\"\\nüîç Extracting embeddings from test samples...\")\n",
    "\n",
    "with torch.no_grad():\n",
    "    for i, sample in enumerate(test_dataset):\n",
    "        # Convert sample to PyTorch tensors\n",
    "        x = torch.tensor(sample['x'], dtype=torch.float).to(device)\n",
    "        edge_index = torch.tensor(sample['edge_index'], dtype=torch.long).to(device)\n",
    "        y = sample['y'][0]  # True complexity score\n",
    "        \n",
    "        # Create batch tensor for single sample\n",
    "        batch = torch.zeros(x.size(0), dtype=torch.long).to(device)\n",
    "        \n",
    "        # Create PyTorch Geometric Data object\n",
    "        data = Data(x=x, edge_index=edge_index, batch=batch)\n",
    "        \n",
    "        # Extract embeddings and predictions\n",
    "        embeddings, predictions = extract_embeddings(model, data)\n",
    "        \n",
    "        # Store results\n",
    "        all_embeddings.append(embeddings.cpu().numpy())\n",
    "        all_predictions.append(predictions.cpu().numpy())\n",
    "        all_true_complexity.append(y)\n",
    "        all_metadata.append({\n",
    "            'id': sample['id'],\n",
    "            'repo_name': sample['repo_name'],\n",
    "            'file_path': sample['file_path']\n",
    "        })\n",
    "        \n",
    "        if (i + 1) % 50 == 0:\n",
    "            print(f\"   Processed {i + 1}/{len(test_dataset)} samples\")\n",
    "\n",
    "# Convert to numpy arrays\n",
    "embeddings_matrix = np.vstack(all_embeddings)\n",
    "predictions_array = np.vstack(all_predictions).flatten()\n",
    "true_complexity_array = np.array(all_true_complexity)\n",
    "\n",
    "print(f\"\\n‚úÖ Extraction complete!\")\n",
    "print(f\"   Embeddings shape: {embeddings_matrix.shape}\")\n",
    "print(f\"   Embedding dimension: {embeddings_matrix.shape[1]}\")\n",
    "print(f\"   Number of samples: {embeddings_matrix.shape[0]}\")\n",
    "print(f\"   Complexity range: {true_complexity_array.min():.1f} - {true_complexity_array.max():.1f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Dimensionality Reduction with t-SNE\n",
    "\n",
    "We'll use t-SNE to project the high-dimensional embeddings into a 2D space for visualization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"üéØ Performing t-SNE dimensionality reduction...\")\n",
    "print(f\"   Input: {embeddings_matrix.shape[1]}D embeddings\")\n",
    "print(f\"   Output: 2D projection\")\n",
    "\n",
    "# Configure t-SNE\n",
    "tsne = TSNE(\n",
    "    n_components=2,\n",
    "    perplexity=min(30, len(embeddings_matrix) // 4),  # Adjust perplexity for smaller datasets\n",
    "    random_state=42,\n",
    "    max_iter=1000,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Apply t-SNE\n",
    "embeddings_2d = tsne.fit_transform(embeddings_matrix)\n",
    "\n",
    "print(f\"\\n‚úÖ t-SNE complete!\")\n",
    "print(f\"   2D embeddings shape: {embeddings_2d.shape}\")\n",
    "print(f\"   X range: [{embeddings_2d[:, 0].min():.2f}, {embeddings_2d[:, 0].max():.2f}]\")\n",
    "print(f\"   Y range: [{embeddings_2d[:, 1].min():.2f}, {embeddings_2d[:, 1].max():.2f}]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Create Visualization\n",
    "\n",
    "Now we'll create a scatter plot of the 2D embeddings, colored by the true complexity scores to see if the model has learned meaningful representations that cluster similar complexity scores together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the main visualization\n",
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "# Create scatter plot colored by complexity score\n",
    "scatter = plt.scatter(\n",
    "    embeddings_2d[:, 0], \n",
    "    embeddings_2d[:, 1], \n",
    "    c=true_complexity_array, \n",
    "    cmap='viridis', \n",
    "    s=60, \n",
    "    alpha=0.7,\n",
    "    edgecolors='black',\n",
    "    linewidth=0.5\n",
    ")\n",
    "\n",
    "# Add colorbar\n",
    "cbar = plt.colorbar(scatter)\n",
    "cbar.set_label('True Complexity Score', fontsize=12, fontweight='bold')\n",
    "\n",
    "# Customize plot\n",
    "plt.title('Ruby Method Complexity: 2D Embedding Visualization\\n(Colored by True Complexity Score)', \n",
    "          fontsize=14, fontweight='bold', pad=20)\n",
    "plt.xlabel('t-SNE Dimension 1', fontsize=12, fontweight='bold')\n",
    "plt.ylabel('t-SNE Dimension 2', fontsize=12, fontweight='bold')\n",
    "\n",
    "# Add grid for better readability\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "# Add text box with statistics\n",
    "stats_text = f\"\"\"Dataset: {len(test_dataset)} Ruby methods\n",
    "Embedding dim: {embeddings_matrix.shape[1]}D ‚Üí 2D\n",
    "Complexity range: {true_complexity_array.min():.1f} - {true_complexity_array.max():.1f}\n",
    "Model: {model_config['conv_type']} GNN\"\"\"\n",
    "\n",
    "plt.text(0.02, 0.98, stats_text, transform=plt.gca().transAxes, \n",
    "         verticalalignment='top', bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.8),\n",
    "         fontsize=10)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"üé® Main visualization complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Analysis: Clustering by Complexity Ranges\n",
    "\n",
    "Let's analyze the clustering behavior by grouping methods into complexity ranges and seeing if they form distinct clusters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define complexity ranges for analysis\n",
    "def categorize_complexity(score):\n",
    "    if score < 5:\n",
    "        return 'Low (< 5)'\n",
    "    elif score < 15:\n",
    "        return 'Medium (5-15)'\n",
    "    elif score < 30:\n",
    "        return 'High (15-30)'\n",
    "    else:\n",
    "        return 'Very High (‚â• 30)'\n",
    "\n",
    "# Categorize all samples\n",
    "complexity_categories = [categorize_complexity(score) for score in true_complexity_array]\n",
    "unique_categories = list(set(complexity_categories))\n",
    "category_counts = {cat: complexity_categories.count(cat) for cat in unique_categories}\n",
    "\n",
    "print(\"üìä Complexity Category Distribution:\")\n",
    "for category, count in sorted(category_counts.items()):\n",
    "    print(f\"   {category}: {count} methods ({count/len(complexity_categories)*100:.1f}%)\")\n",
    "\n",
    "# Create categorical visualization\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "# Left plot: Scatter by categories\n",
    "colors = plt.cm.Set1(np.linspace(0, 1, len(unique_categories)))\n",
    "for i, category in enumerate(sorted(unique_categories)):\n",
    "    mask = [cat == category for cat in complexity_categories]\n",
    "    ax1.scatter(\n",
    "        embeddings_2d[mask, 0], \n",
    "        embeddings_2d[mask, 1], \n",
    "        c=[colors[i]], \n",
    "        label=f'{category} ({sum(mask)} methods)',\n",
    "        s=60, \n",
    "        alpha=0.7,\n",
    "        edgecolors='black',\n",
    "        linewidth=0.5\n",
    "    )\n",
    "\n",
    "ax1.set_title('Embeddings by Complexity Categories', fontsize=12, fontweight='bold')\n",
    "ax1.set_xlabel('t-SNE Dimension 1', fontweight='bold')\n",
    "ax1.set_ylabel('t-SNE Dimension 2', fontweight='bold')\n",
    "ax1.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# Right plot: Distribution of categories\n",
    "category_names = sorted(category_counts.keys())\n",
    "category_values = [category_counts[cat] for cat in category_names]\n",
    "\n",
    "bars = ax2.bar(range(len(category_names)), category_values, color=colors[:len(category_names)])\n",
    "ax2.set_title('Method Count by Complexity Category', fontsize=12, fontweight='bold')\n",
    "ax2.set_xlabel('Complexity Category', fontweight='bold')\n",
    "ax2.set_ylabel('Number of Methods', fontweight='bold')\n",
    "ax2.set_xticks(range(len(category_names)))\n",
    "ax2.set_xticklabels(category_names, rotation=45, ha='right')\n",
    "\n",
    "# Add value labels on bars\n",
    "for bar, value in zip(bars, category_values):\n",
    "    ax2.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.5, \n",
    "             str(value), ha='center', va='bottom', fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nüìà Categorical analysis complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Model Performance Analysis\n",
    "\n",
    "Let's also examine how well our model's predictions correlate with the true complexity scores and if this is reflected in the embedding space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate prediction metrics\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "mae = mean_absolute_error(true_complexity_array, predictions_array)\n",
    "mse = mean_squared_error(true_complexity_array, predictions_array)\n",
    "rmse = np.sqrt(mse)\n",
    "r2 = r2_score(true_complexity_array, predictions_array)\n",
    "\n",
    "print(\"üéØ Model Performance on Test Set:\")\n",
    "print(f\"   Mean Absolute Error (MAE): {mae:.4f}\")\n",
    "print(f\"   Root Mean Square Error (RMSE): {rmse:.4f}\")\n",
    "print(f\"   R¬≤ Score: {r2:.4f}\")\n",
    "\n",
    "# Compare with heuristic baseline (MAE: 4.4617 from README)\n",
    "baseline_mae = 4.4617\n",
    "improvement = ((baseline_mae - mae) / baseline_mae) * 100\n",
    "print(f\"\\nüìä Comparison with Heuristic Baseline:\")\n",
    "print(f\"   Heuristic Baseline MAE: {baseline_mae:.4f}\")\n",
    "print(f\"   GNN Model MAE: {mae:.4f}\")\n",
    "if mae < baseline_mae:\n",
    "    print(f\"   ‚úÖ Improvement: {improvement:.1f}% better than baseline\")\n",
    "else:\n",
    "    print(f\"   ‚ùå Performance: {-improvement:.1f}% worse than baseline\")\n",
    "\n",
    "# Create prediction vs actual plot\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))\n",
    "\n",
    "# Left: Prediction vs Actual\n",
    "ax1.scatter(true_complexity_array, predictions_array, alpha=0.6, s=40)\n",
    "ax1.plot([true_complexity_array.min(), true_complexity_array.max()], \n",
    "         [true_complexity_array.min(), true_complexity_array.max()], \n",
    "         'r--', linewidth=2, label='Perfect Prediction')\n",
    "ax1.set_xlabel('True Complexity Score', fontweight='bold')\n",
    "ax1.set_ylabel('Predicted Complexity Score', fontweight='bold')\n",
    "ax1.set_title(f'Prediction Accuracy\\n(R¬≤ = {r2:.3f}, MAE = {mae:.3f})', fontweight='bold')\n",
    "ax1.legend()\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# Right: Residuals\n",
    "residuals = predictions_array - true_complexity_array\n",
    "ax2.scatter(true_complexity_array, residuals, alpha=0.6, s=40)\n",
    "ax2.axhline(y=0, color='r', linestyle='--', linewidth=2)\n",
    "ax2.set_xlabel('True Complexity Score', fontweight='bold')\n",
    "ax2.set_ylabel('Prediction Error (Predicted - True)', fontweight='bold')\n",
    "ax2.set_title('Prediction Residuals', fontweight='bold')\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nüìä Performance analysis complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Summary and Conclusions\n",
    "\n",
    "Let's summarize our findings about the learned embeddings and their clustering behavior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"üéØ EMBEDDING VISUALIZATION SUMMARY\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "print(f\"\\nüìä Dataset Information:\")\n",
    "print(f\"   ‚Ä¢ Total test samples: {len(test_dataset)}\")\n",
    "print(f\"   ‚Ä¢ Embedding dimension: {embeddings_matrix.shape[1]}D\")\n",
    "print(f\"   ‚Ä¢ Complexity range: {true_complexity_array.min():.1f} - {true_complexity_array.max():.1f}\")\n",
    "\n",
    "print(f\"\\nüß† Model Architecture:\")\n",
    "print(f\"   ‚Ä¢ Type: {model_config['conv_type']} Graph Neural Network\")\n",
    "print(f\"   ‚Ä¢ Layers: {model_config['num_layers']}\")\n",
    "print(f\"   ‚Ä¢ Hidden dimension: {model_config['hidden_dim']}\")\n",
    "print(f\"   ‚Ä¢ Parameters: {sum(p.numel() for p in model.parameters()):,}\")\n",
    "\n",
    "print(f\"\\nüìà Performance Metrics:\")\n",
    "print(f\"   ‚Ä¢ Mean Absolute Error: {mae:.4f}\")\n",
    "print(f\"   ‚Ä¢ R¬≤ Score: {r2:.4f}\")\n",
    "if mae < baseline_mae:\n",
    "    print(f\"   ‚Ä¢ ‚úÖ Beats heuristic baseline by {improvement:.1f}%\")\n",
    "else:\n",
    "    print(f\"   ‚Ä¢ ‚ùå Below heuristic baseline by {-improvement:.1f}%\")\n",
    "\n",
    "print(f\"\\nüé® Visualization Results:\")\n",
    "print(f\"   ‚Ä¢ Successfully created 2D embedding visualization\")\n",
    "print(f\"   ‚Ä¢ Methods colored by true complexity scores\")\n",
    "print(f\"   ‚Ä¢ Complexity categories: {len(unique_categories)} groups\")\n",
    "\n",
    "# Analyze clustering quality\n",
    "print(f\"\\nüîç Clustering Analysis:\")\n",
    "for category in sorted(unique_categories):\n",
    "    count = category_counts[category]\n",
    "    percentage = count / len(complexity_categories) * 100\n",
    "    print(f\"   ‚Ä¢ {category}: {count} methods ({percentage:.1f}%)\")\n",
    "\n",
    "print(f\"\\n‚úÖ CONCLUSION:\")\n",
    "if r2 > 0.3 and mae < baseline_mae:\n",
    "    print(\"   The GNN model has successfully learned meaningful representations!\")\n",
    "    print(\"   The embedding visualization shows evidence of clustering by complexity.\")\n",
    "elif r2 > 0.1:\n",
    "    print(\"   The GNN model shows some learning of structural patterns.\")\n",
    "    print(\"   Further training or architecture improvements may help.\")\n",
    "else:\n",
    "    print(\"   The model shows limited learning of complexity patterns.\")\n",
    "    print(\"   Consider architectural changes or additional training.\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 50)\n",
    "print(\"üéâ Embedding visualization analysis complete!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}