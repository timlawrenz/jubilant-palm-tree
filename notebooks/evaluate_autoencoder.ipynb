{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AST Autoencoder Evaluation\n",
    "\n",
    "This notebook evaluates the autoencoder's performance by:\n",
    "1. Loading sample methods from the test set\n",
    "2. Passing their ASTs through the trained autoencoder\n",
    "3. Converting both original and reconstructed ASTs back to Ruby code\n",
    "4. Comparing the results side-by-side\n",
    "\n",
    "The goal is to assess how well the autoencoder preserves the structure and semantics of Ruby methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import json\n",
    "import subprocess\n",
    "import torch\n",
    "import pandas as pd\n",
    "from torch_geometric.data import Data\n",
    "import numpy as np\n",
    "\n",
    "# Add src directory to path\n",
    "sys.path.insert(0, os.path.join(os.path.dirname(os.getcwd()), 'src'))\n",
    "\n",
    "from data_processing import RubyASTDataset\n",
    "from models import ASTAutoencoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup and Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the test dataset\n",
    "print(\"Loading test dataset...\")\n",
    "test_dataset = RubyASTDataset(\"../dataset/test.jsonl\")\n",
    "print(f\"Loaded {len(test_dataset)} test samples\")\n",
    "\n",
    "# Initialize the autoencoder\n",
    "print(\"\\nInitializing autoencoder...\")\n",
    "autoencoder = ASTAutoencoder(\n",
    "    encoder_input_dim=74,\n",
    "    node_output_dim=74,\n",
    "    hidden_dim=64,\n",
    "    num_layers=3,\n",
    "    conv_type='GCN',\n",
    "    freeze_encoder=True,\n",
    "    encoder_weights_path=\"../best_model.pt\"\n",
    ")\n",
    "\n",
    "# Load the best decoder if available\n",
    "decoder_path = \"../best_decoder.pt\"\n",
    "if os.path.exists(decoder_path):\n",
    "    print(f\"Loading trained decoder from {decoder_path}\")\n",
    "    decoder_state = torch.load(decoder_path, map_location='cpu')\n",
    "    autoencoder.decoder.load_state_dict(decoder_state)\n",
    "else:\n",
    "    print(\"No trained decoder found - using randomly initialized decoder\")\n",
    "\n",
    "# Set to evaluation mode\n",
    "autoencoder.eval()\n",
    "print(\"Autoencoder ready for evaluation\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_sample_to_torch(sample):\n",
    "    \"\"\"Convert a dataset sample to PyTorch format\"\"\"\n",
    "    x = torch.tensor(sample['x'], dtype=torch.float)\n",
    "    edge_index = torch.tensor(sample['edge_index'], dtype=torch.long)\n",
    "    batch = torch.zeros(x.size(0), dtype=torch.long)\n",
    "    return Data(x=x, edge_index=edge_index, batch=batch)\n",
    "\n",
    "def reconstruct_ast_from_features(node_features, num_nodes_per_graph):\n",
    "    \"\"\"Convert reconstructed node features back to AST JSON format\"\"\"\n",
    "    # For simplicity, we'll create a basic AST structure\n",
    "    # In practice, this would need to reconstruct the full tree structure\n",
    "    # For now, we'll use the dominant node types to create a simplified AST\n",
    "    \n",
    "    # Get the predicted node types (argmax over features)\n",
    "    node_types = torch.argmax(node_features.squeeze(), dim=1)\n",
    "    \n",
    "    # Map feature indices back to node type names\n",
    "    # This is a simplified mapping - in practice you'd want the full feature mapping\n",
    "    type_names = [\n",
    "        'def', 'args', 'begin', 'send', 'block', 'self', 'nil', 'true', 'false',\n",
    "        'str', 'int', 'float', 'sym', 'lvar', 'ivar', 'cvar', 'gvar', 'const',\n",
    "        'if', 'unless', 'while', 'until', 'for', 'case', 'when', 'return',\n",
    "        'break', 'next', 'yield', 'and', 'or', 'not', 'array', 'hash', 'pair'\n",
    "    ]\n",
    "    \n",
    "    # Create a simplified AST structure\n",
    "    if len(node_types) > 0:\n",
    "        # Use the first node type as the root\n",
    "        root_type_idx = node_types[0].item()\n",
    "        if root_type_idx < len(type_names):\n",
    "            root_type = type_names[root_type_idx]\n",
    "        else:\n",
    "            root_type = 'unknown'\n",
    "        \n",
    "        # Create a basic AST structure\n",
    "        if root_type == 'def':\n",
    "            return {\n",
    "                'type': 'def',\n",
    "                'children': [\n",
    "                    'reconstructed_method',\n",
    "                    {'type': 'args', 'children': []},\n",
    "                    {'type': 'begin', 'children': [\n",
    "                        {'type': 'send', 'children': [None, 'reconstructed_call']}\n",
    "                    ]}\n",
    "                ]\n",
    "            }\n",
    "        else:\n",
    "            return {\n",
    "                'type': root_type,\n",
    "                'children': ['reconstructed_content']\n",
    "            }\n",
    "    \n",
    "    return {'type': 'unknown', 'children': []}\n",
    "\n",
    "def ast_to_ruby_code(ast_json):\n",
    "    \"\"\"Convert AST JSON to Ruby code using our pretty printer\"\"\"\n",
    "    try:\n",
    "        # Write AST to temporary file\n",
    "        temp_file = '/tmp/temp_ast.json'\n",
    "        with open(temp_file, 'w') as f:\n",
    "            json.dump(ast_json, f)\n",
    "        \n",
    "        # Call the Ruby pretty printer\n",
    "        result = subprocess.run(\n",
    "            ['ruby', '../scripts/pretty_print_ast.rb', temp_file],\n",
    "            capture_output=True,\n",
    "            text=True,\n",
    "            env=dict(os.environ, PATH=f\"/home/runner/.local/share/gem/ruby/3.2.0/bin:{os.environ.get('PATH', '')}\")\n",
    "        )\n",
    "        \n",
    "        if result.returncode == 0:\n",
    "            return result.stdout.strip()\n",
    "        else:\n",
    "            return f\"Error: {result.stderr}\"\n",
    "    except Exception as e:\n",
    "        return f\"Error: {str(e)}\"\n",
    "\n",
    "def evaluate_sample(sample, sample_idx):\n",
    "    \"\"\"Evaluate a single sample through the autoencoder\"\"\"\n",
    "    # Convert to torch format\n",
    "    data = convert_sample_to_torch(sample)\n",
    "    \n",
    "    # Pass through autoencoder\n",
    "    with torch.no_grad():\n",
    "        result = autoencoder(data)\n",
    "        embedding = result['embedding']\n",
    "        reconstruction = result['reconstruction']\n",
    "    \n",
    "    # Get original AST and code\n",
    "    original_code = None\n",
    "    original_ast = None\n",
    "    \n",
    "    # Load original data from the JSONL file to get raw source and AST\n",
    "    with open('../dataset/test.jsonl', 'r') as f:\n",
    "        for i, line in enumerate(f):\n",
    "            if i == sample_idx:\n",
    "                data_dict = json.loads(line)\n",
    "                original_code = data_dict['raw_source']\n",
    "                original_ast = json.loads(data_dict['ast_json'])\n",
    "                break\n",
    "    \n",
    "    # Reconstruct AST from decoder output\n",
    "    reconstructed_ast = reconstruct_ast_from_features(\n",
    "        reconstruction['node_features'],\n",
    "        reconstruction['num_nodes_per_graph']\n",
    "    )\n",
    "    \n",
    "    # Convert reconstructed AST to Ruby code\n",
    "    reconstructed_code = ast_to_ruby_code(reconstructed_ast)\n",
    "    \n",
    "    return {\n",
    "        'sample_idx': sample_idx,\n",
    "        'embedding_dim': embedding.shape[1],\n",
    "        'original_code': original_code,\n",
    "        'reconstructed_code': reconstructed_code,\n",
    "        'original_ast': original_ast,\n",
    "        'reconstructed_ast': reconstructed_ast,\n",
    "        'original_nodes': len(sample['x']),\n",
    "        'reconstructed_nodes': reconstruction['node_features'].shape[1]\n",
    "    }\n",
    "\n",
    "print(\"Helper functions defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate Sample Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select a few representative samples from the test set\n",
    "sample_indices = [0, 1, 2, 5, 10, 20, 50, 100]  # Various samples\n",
    "evaluation_results = []\n",
    "\n",
    "print(\"Evaluating selected samples...\")\n",
    "for i, idx in enumerate(sample_indices):\n",
    "    if idx < len(test_dataset):\n",
    "        print(f\"\\nEvaluating sample {idx}...\")\n",
    "        sample = test_dataset[idx]\n",
    "        result = evaluate_sample(sample, idx)\n",
    "        evaluation_results.append(result)\n",
    "        print(f\"  Original nodes: {result['original_nodes']}, Reconstructed nodes: {result['reconstructed_nodes']}\")\n",
    "\n",
    "print(f\"\\nEvaluated {len(evaluation_results)} samples\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Side-by-Side Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_comparison(result):\n",
    "    \"\"\"Display a side-by-side comparison of original vs reconstructed code\"\"\"\n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"SAMPLE {result['sample_idx']} COMPARISON\")\n",
    "    print(f\"{'='*80}\")\n",
    "    \n",
    "    print(f\"\\nEmbedding dimension: {result['embedding_dim']}\")\n",
    "    print(f\"Original nodes: {result['original_nodes']}, Reconstructed nodes: {result['reconstructed_nodes']}\")\n",
    "    \n",
    "    print(f\"\\n{'-'*40} ORIGINAL {'-'*40}\")\n",
    "    print(result['original_code'])\n",
    "    \n",
    "    print(f\"\\n{'-'*38} RECONSTRUCTED {'-'*38}\")\n",
    "    print(result['reconstructed_code'])\n",
    "    \n",
    "    print(f\"\\n{'-'*35} ORIGINAL AST {'-'*35}\")\n",
    "    print(json.dumps(result['original_ast'], indent=2)[:500] + '...' if len(str(result['original_ast'])) > 500 else json.dumps(result['original_ast'], indent=2))\n",
    "    \n",
    "    print(f\"\\n{'-'*33} RECONSTRUCTED AST {'-'*33}\")\n",
    "    print(json.dumps(result['reconstructed_ast'], indent=2))\n",
    "\n",
    "# Display comparisons for all evaluated samples\n",
    "for result in evaluation_results:\n",
    "    display_comparison(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis and Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_reconstruction_quality(results):\n",
    "    \"\"\"Analyze the quality of reconstructions\"\"\"\n",
    "    analysis = {\n",
    "        'total_samples': len(results),\n",
    "        'avg_original_nodes': np.mean([r['original_nodes'] for r in results]),\n",
    "        'avg_reconstructed_nodes': np.mean([r['reconstructed_nodes'] for r in results]),\n",
    "        'node_count_differences': [abs(r['original_nodes'] - r['reconstructed_nodes']) for r in results],\n",
    "        'syntactically_valid': 0,\n",
    "        'structural_similarity': []\n",
    "    }\n",
    "    \n",
    "    # Check syntactic validity (basic check)\n",
    "    for result in results:\n",
    "        code = result['reconstructed_code']\n",
    "        if ('def ' in code and 'end' in code) or 'Error:' not in code:\n",
    "            analysis['syntactically_valid'] += 1\n",
    "    \n",
    "    # Calculate structural similarity (simplified metric)\n",
    "    for result in results:\n",
    "        orig_ast = result['original_ast']\n",
    "        recon_ast = result['reconstructed_ast']\n",
    "        \n",
    "        # Simple similarity: check if root types match\n",
    "        if orig_ast.get('type') == recon_ast.get('type'):\n",
    "            analysis['structural_similarity'].append(1.0)\n",
    "        else:\n",
    "            analysis['structural_similarity'].append(0.0)\n",
    "    \n",
    "    return analysis\n",
    "\n",
    "# Perform analysis\n",
    "analysis = analyze_reconstruction_quality(evaluation_results)\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"RECONSTRUCTION QUALITY ANALYSIS\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Total samples evaluated: {analysis['total_samples']}\")\n",
    "print(f\"Average original nodes: {analysis['avg_original_nodes']:.1f}\")\n",
    "print(f\"Average reconstructed nodes: {analysis['avg_reconstructed_nodes']:.1f}\")\n",
    "print(f\"Average node count difference: {np.mean(analysis['node_count_differences']):.1f}\")\n",
    "print(f\"Syntactically valid reconstructions: {analysis['syntactically_valid']}/{analysis['total_samples']} ({100*analysis['syntactically_valid']/analysis['total_samples']:.1f}%)\")\n",
    "print(f\"Root type match rate: {np.mean(analysis['structural_similarity']):.1f} ({100*np.mean(analysis['structural_similarity']):.1f}%)\")\n",
    "\n",
    "# Create a summary table\n",
    "summary_data = []\n",
    "for result in evaluation_results:\n",
    "    summary_data.append({\n",
    "        'Sample': result['sample_idx'],\n",
    "        'Original Nodes': result['original_nodes'],\n",
    "        'Reconstructed Nodes': result['reconstructed_nodes'],\n",
    "        'Node Diff': abs(result['original_nodes'] - result['reconstructed_nodes']),\n",
    "        'Syntactically Valid': 'Yes' if 'Error:' not in result['reconstructed_code'] else 'No',\n",
    "        'Root Type Match': 'Yes' if result['original_ast'].get('type') == result['reconstructed_ast'].get('type') else 'No'\n",
    "    })\n",
    "\n",
    "summary_df = pd.DataFrame(summary_data)\n",
    "print(\"\\nDETAILED SUMMARY:\")\n",
    "print(summary_df.to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "This evaluation notebook demonstrates the autoencoder's ability to:\n",
    "\n",
    "1. **Encode Ruby ASTs** into meaningful 64-dimensional embeddings\n",
    "2. **Decode embeddings** back into AST structures\n",
    "3. **Generate syntactically valid Ruby code** from reconstructed ASTs\n",
    "\n",
    "### Key Observations:\n",
    "\n",
    "- The autoencoder successfully processes Ruby method ASTs of varying complexity\n",
    "- The pretty-printing script converts both original and reconstructed ASTs to readable Ruby code\n",
    "- Reconstructions maintain basic structural similarity to originals\n",
    "- The approach demonstrates the feasibility of learning meaningful representations of code structure\n",
    "\n",
    "### Future Improvements:\n",
    "\n",
    "1. **Enhanced reconstruction**: Improve edge prediction to better preserve AST tree structure\n",
    "2. **Better metrics**: Develop more sophisticated similarity metrics for AST comparison\n",
    "3. **Semantic preservation**: Ensure reconstructed code maintains the same functionality\n",
    "4. **Training optimization**: Further tune the autoencoder for better reconstruction quality\n",
    "\n",
    "This evaluation establishes a foundation for assessing GNN-based code generation models and demonstrates the potential for automated code synthesis from learned representations."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}