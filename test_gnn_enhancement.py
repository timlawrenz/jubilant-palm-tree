#!/usr/bin/env python3
"""
Test script to validate the GNN enhancement in AutoregressiveASTDecoder.

This test demonstrates that the new GNN-based graph encoder provides
richer structural representations compared to simple mean pooling.
"""

import torch
import sys
import os
sys.path.insert(0, os.path.join(os.path.dirname(__file__), 'src'))

from models import AutoregressiveASTDecoder


def test_gnn_vs_mean_pooling():
    """Test that GNN encoder provides different outputs for structurally different graphs."""
    print("Testing GNN enhancement: Structural sensitivity...")
    
    decoder = AutoregressiveASTDecoder()
    text_embedding = torch.randn(2, 64)
    
    # Create two graphs with same nodes but different structures
    # Graph 1: Linear structure (0-1-2)
    graph1 = {
        'x': torch.tensor([[1.0] + [0.0] * 73, [0.0, 1.0] + [0.0] * 72, [0.0, 0.0, 1.0] + [0.0] * 71]),  # Different node types
        'edge_index': torch.tensor([[0, 1, 1, 2], [1, 0, 2, 1]]),  # Linear: 0-1-2
        'batch': torch.tensor([0, 0, 0])
    }
    
    # Graph 2: Star structure (1 is center, connected to 0 and 2)  
    graph2 = {
        'x': torch.tensor([[1.0] + [0.0] * 73, [0.0, 1.0] + [0.0] * 72, [0.0, 0.0, 1.0] + [0.0] * 71]),  # Same node types
        'edge_index': torch.tensor([[0, 1, 1, 2], [1, 0, 1, 2]]),  # Star: 1 connected to both 0 and 2
        'batch': torch.tensor([0, 0, 0])
    }
    
    # Get outputs for both structures
    with torch.no_grad():
        output1 = decoder(text_embedding[:1], graph1)
        output2 = decoder(text_embedding[:1], graph2)
    
    # Compare node type predictions
    logits1 = output1['node_type_logits']
    logits2 = output2['node_type_logits']
    
    # Calculate difference in predictions
    diff = torch.abs(logits1 - logits2).max().item()
    
    print(f"âœ… GNN structural sensitivity test:")
    print(f"   Maximum difference in predictions: {diff:.6f}")
    
    if diff > 1e-6:
        print(f"âœ… GNN encoder is structure-sensitive (good!)")
        print(f"   Different graph structures produce different outputs")
    else:
        print(f"âš ï¸  GNN encoder may not be fully utilizing structural information")
    
    return diff > 1e-6


def test_gnn_complexity():
    """Test that GNN can handle graphs of different complexities."""
    print("\nTesting GNN with varying graph complexities...")
    
    decoder = AutoregressiveASTDecoder()
    text_embedding = torch.randn(1, 64)
    
    complexities = []
    
    # Simple graph (2 nodes)
    simple_graph = {
        'x': torch.tensor([[1.0] + [0.0] * 73, [0.0, 1.0] + [0.0] * 72]),
        'edge_index': torch.tensor([[0, 1], [1, 0]]),
        'batch': torch.tensor([0, 0])
    }
    
    # Complex graph (5 nodes, more edges)
    complex_graph = {
        'x': torch.tensor([[1.0] + [0.0] * 73, [0.0, 1.0] + [0.0] * 72, [0.0, 0.0, 1.0] + [0.0] * 71, 
                          [0.0] * 3 + [1.0] + [0.0] * 70, [0.0] * 4 + [1.0] + [0.0] * 69]),
        'edge_index': torch.tensor([[0, 1, 1, 2, 2, 3, 3, 4, 0, 4], [1, 0, 2, 1, 3, 2, 4, 3, 4, 0]]),
        'batch': torch.tensor([0, 0, 0, 0, 0])
    }
    
    with torch.no_grad():
        output_simple = decoder(text_embedding, simple_graph)
        output_complex = decoder(text_embedding, complex_graph)
    
    # Compare outputs - compute entropy manually
    simple_probs = torch.softmax(output_simple['node_type_logits'], dim=-1)
    complex_probs = torch.softmax(output_complex['node_type_logits'], dim=-1)
    
    # Compute entropy: -sum(p * log(p))
    simple_entropy = -(simple_probs * torch.log(simple_probs + 1e-8)).sum().item()
    complex_entropy = -(complex_probs * torch.log(complex_probs + 1e-8)).sum().item()
    
    print(f"âœ… GNN complexity handling:")
    print(f"   Simple graph prediction entropy: {simple_entropy:.4f}")
    print(f"   Complex graph prediction entropy: {complex_entropy:.4f}")
    print(f"   GNN adapts to different graph complexities")
    
    return True


def test_edge_importance():
    """Test that edges matter in GNN processing."""
    print("\nTesting importance of edge structure...")
    
    decoder = AutoregressiveASTDecoder()
    text_embedding = torch.randn(1, 64)
    
    # Same nodes, with edges
    graph_with_edges = {
        'x': torch.tensor([[1.0] + [0.0] * 73, [0.0, 1.0] + [0.0] * 72, [0.0, 0.0, 1.0] + [0.0] * 71]),
        'edge_index': torch.tensor([[0, 1, 1, 2], [1, 0, 2, 1]]),
        'batch': torch.tensor([0, 0, 0])
    }
    
    # Same nodes, no edges (isolated nodes)
    graph_without_edges = {
        'x': torch.tensor([[1.0] + [0.0] * 73, [0.0, 1.0] + [0.0] * 72, [0.0, 0.0, 1.0] + [0.0] * 71]),
        'edge_index': torch.empty((2, 0), dtype=torch.long),
        'batch': torch.tensor([0, 0, 0])
    }
    
    with torch.no_grad():
        output_with_edges = decoder(text_embedding, graph_with_edges)
        output_without_edges = decoder(text_embedding, graph_without_edges)
    
    # Compare outputs
    diff = torch.abs(output_with_edges['node_type_logits'] - output_without_edges['node_type_logits']).max().item()
    
    print(f"âœ… Edge structure importance:")
    print(f"   Difference with/without edges: {diff:.6f}")
    
    if diff > 1e-6:
        print(f"âœ… Edge structure significantly affects GNN output")
    else:
        print(f"âš ï¸  Edge structure may not be fully utilized")
    
    return diff > 1e-6


def main():
    """Run all GNN enhancement tests."""
    print("ğŸš€ Testing GNN Enhancement in AutoregressiveASTDecoder")
    print("=" * 60)
    
    results = []
    
    # Test structural sensitivity
    results.append(test_gnn_vs_mean_pooling())
    
    # Test complexity handling
    results.append(test_gnn_complexity())
    
    # Test edge importance
    results.append(test_edge_importance())
    
    print("\n" + "=" * 60)
    print(f"ğŸ GNN Enhancement Results: {sum(results)}/{len(results)} tests passed")
    
    if all(results):
        print("âœ… GNN enhancement successfully provides rich structural representations!")
    else:
        print("âš ï¸  Some aspects of GNN enhancement may need further refinement")
    
    return all(results)


if __name__ == "__main__":
    success = main()
    exit(0 if success else 1)