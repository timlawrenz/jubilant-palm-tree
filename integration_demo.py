#!/usr/bin/env python3
"""
Integration demonstration showing how the data pipeline works with the GNN model.

This script shows how the implemented dataset and DataLoader integrate with
the existing RubyComplexityGNN model for training.
"""

import sys
import os

# Add src directory to path
sys.path.insert(0, os.path.join(os.path.dirname(__file__), 'src'))

from data_processing import create_data_loaders, RubyASTDataset


def demonstrate_model_integration():
    """Show how the data pipeline integrates with the GNN model."""
    print("ðŸ”— Model Integration Demonstration")
    print("=" * 50)
    
    # Create data loaders
    print("Creating data loaders...")
    train_loader, val_loader = create_data_loaders(
        "dataset/train.jsonl",
        "dataset/validation.jsonl", 
        batch_size=4  # Small batch for demo
    )
    
    # Get feature dimension
    dataset = RubyASTDataset("dataset/train.jsonl")
    feature_dim = dataset.get_feature_dim()
    
    print(f"âœ… Data loaders created")
    print(f"   Feature dimension: {feature_dim}")
    print(f"   Train batches: {len(train_loader)}")
    print(f"   Validation batches: {len(val_loader)}")
    
    # Show model integration code
    print(f"\nðŸ§  Model Integration Code:")
    print("```python")
    print("# Import required libraries (when available)")
    print("import torch")
    print("import torch.nn.functional as F")
    print("from torch_geometric.data import Data")
    print("from src.models import RubyComplexityGNN")
    print("from src.data_processing import create_data_loaders")
    print("")
    print("# Initialize model with correct input dimension")
    print(f"model = RubyComplexityGNN(input_dim={feature_dim}, hidden_dim=64, num_layers=3)")
    print("optimizer = torch.optim.Adam(model.parameters(), lr=0.001)")
    print("criterion = torch.nn.MSELoss()")
    print("")
    print("# Create data loaders")
    print("train_loader, val_loader = create_data_loaders(")
    print("    'dataset/train.jsonl', 'dataset/validation.jsonl', batch_size=32")
    print(")")
    print("")
    print("# Training loop")
    print("model.train()")
    print("for epoch in range(num_epochs):")
    print("    total_loss = 0")
    print("    for batch in train_loader:")
    print("        # Convert to PyTorch tensors")
    print("        x = torch.tensor(batch['x'], dtype=torch.float)")
    print("        edge_index = torch.tensor(batch['edge_index'], dtype=torch.long)")
    print("        y = torch.tensor(batch['y'], dtype=torch.float)")
    print("        batch_idx = torch.tensor(batch['batch'], dtype=torch.long)")
    print("")
    print("        # Create PyTorch Geometric Data object")
    print("        data = Data(x=x, edge_index=edge_index, batch=batch_idx)")
    print("")
    print("        # Forward pass")
    print("        optimizer.zero_grad()")
    print("        pred = model(data)")
    print("        loss = criterion(pred.squeeze(), y)")
    print("")
    print("        # Backward pass")
    print("        loss.backward()")
    print("        optimizer.step()")
    print("        total_loss += loss.item()")
    print("")
    print("    avg_loss = total_loss / len(train_loader)")
    print("    print(f'Epoch {epoch}: Loss = {avg_loss:.4f}')")
    print("```")
    
    # Show sample batch processing
    print(f"\nðŸ“Š Sample Batch Processing:")
    batch = next(iter(train_loader))
    
    print(f"Sample batch contains:")
    print(f"  â€¢ {batch['num_graphs']} graphs")
    print(f"  â€¢ {len(batch['x'])} total nodes")
    print(f"  â€¢ {len(batch['edge_index'][0])} total edges")
    print(f"  â€¢ Target complexity scores: {batch['y']}")
    print(f"  â€¢ Node feature vectors: {len(batch['x'])} x {len(batch['x'][0])}")
    print(f"  â€¢ Edge connectivity: 2 x {len(batch['edge_index'][0])}")
    print(f"  â€¢ Batch indices: {len(batch['batch'])} (for graph pooling)")
    
    # Show compatibility with existing model
    print(f"\nðŸŽ¯ Model Compatibility:")
    print("The data format is directly compatible with the existing RubyComplexityGNN model:")
    print(f"  â€¢ Input dimension matches: {feature_dim} features")
    print("  â€¢ Edge format: PyTorch Geometric standard [2, num_edges]")
    print("  â€¢ Batch format: Compatible with global_mean_pool")
    print("  â€¢ Target format: Regression targets for complexity prediction")
    
    print(f"\nâœ… Integration demonstration complete!")
    print("The data pipeline is ready for GNN training with the existing model architecture.")


if __name__ == "__main__":
    demonstrate_model_integration()